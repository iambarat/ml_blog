{
  "hash": "639fcafb539668dbb09072b149bf2097",
  "result": {
    "markdown": "---\ntitle: \"Understanding Classification\"\nauthor: \"Mohaimin\"\ndate: \"2023-12-03\"\nformat: html\n---\n\n# Introduction to Classification in Machine Learning\n\nClassification is a cornerstone of machine learning, where we teach a computer how to make decisions from data. It involves categorizing data into predefined classes. In this post, we'll explore the basics of classification in machine learning using Python, a popular language in data science due to its simplicity and robust libraries.\n\n\n## Classification Basics\n\nClassification algorithms represent a fundamental aspect of supervised learning in machine learning. These algorithms focus on categorizing new observations into predefined classes or groups based on a dataset of labeled examples. In simpler terms, classification involves using these algorithms to predict the category or class of new, unseen instances.\n\nThe essence of classification is to \"learn\" from a dataset where the categories (or labels) of observations are known, and then apply this learned pattern to predict the class of new observations. Common examples include binary classifications like Yes or No, 0 or 1, Spam or Not Spam, and multi-class scenarios like distinguishing between different types of animals, colors, or objects. In contrast to regression, where the output is a continuous value, the output of a classification algorithm is categorical. These categories, also known as labels or targets, are discrete and typically non-numeric. For instance, categories might be \"Red\" or \"Blue\", \"Cat\" or \"Dog\", \"Spam\" or \"Not Spam\". \n\nAs a supervised learning technique, classification relies on labeled input data. This means that the training data includes both the input features and the corresponding output labels. The algorithm learns to associate specific input patterns with particular output categories, enabling it to make predictions for new, unlabeled data.\n\n\n### Types of Classification\n\n**Binary Classification:** Involves two classes. For example, determining whether an email is spam. \n\n**Multiclass Classification:** Involves more than two classes. For instance, classifying types of crops.\n\n### Implementing Classification in Python\n\nWe'll use the Iris dataset, a classic in machine learning, which includes data on various iris flowers and classifies them into three species.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n#loading dataset\nfrom sklearn.datasets import load_iris\niris = load_iris()\n\n#splitting dataset\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    iris.data, iris.target, test_size=0.3, random_state=42)\n\n#knn\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\n\n#knn_evaluation\nfrom sklearn.metrics import accuracy_score\ny_pred = knn.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\n\n### Decision Tree Classifier\n\nfrom sklearn.tree import DecisionTreeClassifier\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, y_train)\n\n#evaluation\ny_pred_dt = decision_tree.predict(X_test)\naccuracy_dt = accuracy_score(y_test, y_pred_dt)\nprint(f\"Decision Tree Accuracy: {accuracy_dt:.2f}\")\n\n#support vector machine classifier\nfrom sklearn.svm import SVC\n\n#training\nsvm = SVC()\nsvm.fit(X_train, y_train)\n\n#evaluating\ny_pred_svm = svm.predict(X_test)\naccuracy_svm = accuracy_score(y_test, y_pred_svm)\nprint(f\"SVM Accuracy: {accuracy_svm:.2f}\")\n\n\n# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\n\nlog_reg = LogisticRegression(max_iter=200)\nlog_reg.fit(X_train, y_train)\n\n# Evaluating\ny_pred_lr = log_reg.predict(X_test)\naccuracy_lr = accuracy_score(y_test, y_pred_lr)\nprint(f\"Logistic Regression Accuracy: {accuracy_lr:.2f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy: 1.00\nDecision Tree Accuracy: 1.00\nSVM Accuracy: 1.00\nLogistic Regression Accuracy: 1.00\n```\n:::\n:::\n\n\n### Conclusion\n\nIn this post, we've explored various classification algorithms, each with its unique strengths. Choosing the right classifier depends on the dataset's size, quality, and nature. Experimentation and cross-validation are key to determining the most effective model for your specific data.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}