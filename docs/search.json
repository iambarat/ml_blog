[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/random_variable/index.html",
    "href": "posts/random_variable/index.html",
    "title": "Understanding Random Variables",
    "section": "",
    "text": "In this post, we’ll explore the concept of random variables in the context of machine learning using Python. Understanding random variables is essential for grasping the fundamentals of probabilistic models and statistical methods in machine learning.\n\n\nA random variable is a variable whose possible values are numerical outcomes of a random phenomenon. In machine learning, they are key to modeling uncertainties and probabilities.\n\n\n\n\nPython, with libraries like numpy and matplotlib, is a powerful tool for statistical simulations. Let’s demonstrate this with some examples.\n\n\nFirst, we’ll simulate a discrete random variable: the outcome of a dice roll.\n\nlibrary(reticulate)\nuse_python(\"/Users/bota/Files/VT/Course Materials/Fall 23/ML Blog/vscode/mlblog/bin/python\")\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Setting a seed for reproducibility\nnp.random.seed(123)\n\n# Simulating dice rolls\ndice_rolls = np.random.choice([1, 2, 3, 4, 5, 6], size=1000)\n\n# Plotting the results\nplt.hist(dice_rolls, bins=np.arange(1, 8) - 0.5, rwidth=0.8)\nplt.title('Dice Roll Distribution')\nplt.xlabel('Dice Value')\nplt.ylabel('Frequency')\nplt.xticks(range(1, 7))\n\n([&lt;matplotlib.axis.XTick object at 0x16a5a67d0&gt;, &lt;matplotlib.axis.XTick object at 0x137d59c90&gt;, &lt;matplotlib.axis.XTick object at 0x16a5cb150&gt;, &lt;matplotlib.axis.XTick object at 0x16a5f0390&gt;, &lt;matplotlib.axis.XTick object at 0x16a5f4390&gt;, &lt;matplotlib.axis.XTick object at 0x16a5f6450&gt;], [Text(1, 0, '1'), Text(2, 0, '2'), Text(3, 0, '3'), Text(4, 0, '4'), Text(5, 0, '5'), Text(6, 0, '6')])\n\nplt.show()\n\n\n\n# Simulating a normal distribution\nnormal_data = np.random.normal(loc=0, scale=1, size=1000)\n\n# Plotting the results\nplt.hist(normal_data, bins=30, density=True, alpha=0.6, color='g')\nplt.title('Normal Distribution')\nplt.xlabel('Value')\nplt.ylabel('Density')\nplt.show()"
  },
  {
    "objectID": "posts/random_variable/index.html#introduction",
    "href": "posts/random_variable/index.html#introduction",
    "title": "Understanding Random Variables",
    "section": "",
    "text": "In this post, we’ll explore the concept of random variables in the context of machine learning using Python. Understanding random variables is essential for grasping the fundamentals of probabilistic models and statistical methods in machine learning.\n\n\nA random variable is a variable whose possible values are numerical outcomes of a random phenomenon. In machine learning, they are key to modeling uncertainties and probabilities."
  },
  {
    "objectID": "posts/random_variable/index.html#simulating-random-variables-in-python",
    "href": "posts/random_variable/index.html#simulating-random-variables-in-python",
    "title": "Understanding Random Variables",
    "section": "",
    "text": "Python, with libraries like numpy and matplotlib, is a powerful tool for statistical simulations. Let’s demonstrate this with some examples.\n\n\nFirst, we’ll simulate a discrete random variable: the outcome of a dice roll.\n\nlibrary(reticulate)\nuse_python(\"/Users/bota/Files/VT/Course Materials/Fall 23/ML Blog/vscode/mlblog/bin/python\")\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Setting a seed for reproducibility\nnp.random.seed(123)\n\n# Simulating dice rolls\ndice_rolls = np.random.choice([1, 2, 3, 4, 5, 6], size=1000)\n\n# Plotting the results\nplt.hist(dice_rolls, bins=np.arange(1, 8) - 0.5, rwidth=0.8)\nplt.title('Dice Roll Distribution')\nplt.xlabel('Dice Value')\nplt.ylabel('Frequency')\nplt.xticks(range(1, 7))\n\n([&lt;matplotlib.axis.XTick object at 0x16a5a67d0&gt;, &lt;matplotlib.axis.XTick object at 0x137d59c90&gt;, &lt;matplotlib.axis.XTick object at 0x16a5cb150&gt;, &lt;matplotlib.axis.XTick object at 0x16a5f0390&gt;, &lt;matplotlib.axis.XTick object at 0x16a5f4390&gt;, &lt;matplotlib.axis.XTick object at 0x16a5f6450&gt;], [Text(1, 0, '1'), Text(2, 0, '2'), Text(3, 0, '3'), Text(4, 0, '4'), Text(5, 0, '5'), Text(6, 0, '6')])\n\nplt.show()\n\n\n\n# Simulating a normal distribution\nnormal_data = np.random.normal(loc=0, scale=1, size=1000)\n\n# Plotting the results\nplt.hist(normal_data, bins=30, density=True, alpha=0.6, color='g')\nplt.title('Normal Distribution')\nplt.xlabel('Value')\nplt.ylabel('Density')\nplt.show()"
  },
  {
    "objectID": "posts/clustering/index.html",
    "href": "posts/clustering/index.html",
    "title": "Clustering",
    "section": "",
    "text": "Machine learning is a field that has transformed the way we analyze and extract insights from data. One of the fundamental techniques in this field is clustering. Clustering allows us to group similar data points together based on their features or characteristics, making it an essential tool for various applications like customer segmentation, anomaly detection, and more.\nIn this blog post, we will dive into the world of clustering in machine learning using Python within the RStudio environment. We’ll explore the concept of clustering, discuss some common clustering algorithms, and provide practical examples.\n\n\n\nClustering is a type of unsupervised learning where we aim to identify natural groupings within a dataset. Unlike supervised learning, clustering does not require labeled data. Instead, it divides the data into clusters based on the inherent similarities between data points.\n\n\nOne of the most popular clustering algorithms is K-Means. K-Means partitions the data into ‘K’ clusters, with each cluster represented by its centroid. The algorithm iteratively assigns data points to the nearest centroid and updates the centroids until convergence.\nHere’s a Python example using scikit-learn to perform K-Means clustering:\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n\n# Generate random data for demonstration\ndata = np.random.rand(100, 2)\n\n# Create a K-Means model with 3 clusters\nkmeans = KMeans(n_clusters=3)\nkmeans.fit(data)\n\n# Visualize the clustering results\nplt.scatter(data[:, 0], data[:, 1], c=kmeans.labels_)\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, marker='X', c='red', label='Centroids')\nplt.title(\"K-Means Clustering\")\nplt.legend()\nplt.show()\n\n/Users/bota/Files/VT/Course Materials/Fall 23/ML Blog/vscode/mlblog/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)"
  },
  {
    "objectID": "posts/clustering/index.html#introduction",
    "href": "posts/clustering/index.html#introduction",
    "title": "Clustering",
    "section": "",
    "text": "Machine learning is a field that has transformed the way we analyze and extract insights from data. One of the fundamental techniques in this field is clustering. Clustering allows us to group similar data points together based on their features or characteristics, making it an essential tool for various applications like customer segmentation, anomaly detection, and more.\nIn this blog post, we will dive into the world of clustering in machine learning using Python within the RStudio environment. We’ll explore the concept of clustering, discuss some common clustering algorithms, and provide practical examples."
  },
  {
    "objectID": "posts/clustering/index.html#what-is-clustering",
    "href": "posts/clustering/index.html#what-is-clustering",
    "title": "Clustering",
    "section": "",
    "text": "Clustering is a type of unsupervised learning where we aim to identify natural groupings within a dataset. Unlike supervised learning, clustering does not require labeled data. Instead, it divides the data into clusters based on the inherent similarities between data points.\n\n\nOne of the most popular clustering algorithms is K-Means. K-Means partitions the data into ‘K’ clusters, with each cluster represented by its centroid. The algorithm iteratively assigns data points to the nearest centroid and updates the centroids until convergence.\nHere’s a Python example using scikit-learn to perform K-Means clustering:\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n\n# Generate random data for demonstration\ndata = np.random.rand(100, 2)\n\n# Create a K-Means model with 3 clusters\nkmeans = KMeans(n_clusters=3)\nkmeans.fit(data)\n\n# Visualize the clustering results\nplt.scatter(data[:, 0], data[:, 1], c=kmeans.labels_)\nplt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, marker='X', c='red', label='Centroids')\nplt.title(\"K-Means Clustering\")\nplt.legend()\nplt.show()\n\n/Users/bota/Files/VT/Course Materials/Fall 23/ML Blog/vscode/mlblog/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  super()._check_params_vs_input(X, default_n_init=10)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning Blog",
    "section": "",
    "text": "Clustering\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nUnderstanding Random Variables\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  }
]