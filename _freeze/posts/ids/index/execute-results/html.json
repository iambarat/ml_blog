{
  "hash": "8dce19c37e122063976ae907bbc7cc64",
  "result": {
    "markdown": "---\ntitle: \"Anomaly Detection\"\nauthor: \"Mohaimin\"\ndate: \"2023-12-04\"\nformat: html\ncategories: [code]\n---\n\n# Introduction\n\nAnomaly detection, also known as outlier detection, is a fascinating area of machine learning aimed at identifying abnormal patterns that do not conform to expected behavior. These anomalies can be crucial in various domains like fraud detection, system health monitoring, and outlier detection in data cleaning and preprocessing.\n\nIn this blog, we'll dive deep into the world of anomaly detection, exploring its concepts, methodologies, and implementation using Python.\n\n## Fundamentals of Anomaly Detection\n\nAnomaly detection focuses on identifying data points, events, or observations that deviate significantly from the dataset's norm. Mathematically, if we consider a dataset $ D $ containing elements $ x_1, x_2, ..., x_n $, an anomaly $ x_i $ is a point that deviates significantly from the majority of points in $ D $.\n\n### Types of Anomalies\n\n1. **Point Anomalies**: Single data points that are far from the rest of the data.\n2. **Contextual Anomalies**: Abnormalities in a specific context but not otherwise.\n3. **Collective Anomalies**: A collection of data points that are anomalous in relation to the entire dataset.\n\n## Implementing Anomaly Detection in Python\n\nWe'll use the `scikit-learn` library in Python to demonstrate anomaly detection. Ensure you have it installed:\n\n\n```{bash}\npip install scikit-learn\n```\n\n\nWe'll use a simple dataset and Isolation Forest algorithm to detect anomaly for this example.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nfrom sklearn.ensemble import IsolationForest\nimport matplotlib.pyplot as plt\n\n# Generating sample data\nrng = np.random.RandomState(42)\nX = 0.3 * rng.randn(100, 2)\nX_train = np.r_[X + 2, X - 2]\n\n# Adding outliers\nX_outliers = rng.uniform(low=-4, high=4, size=(20, 2))\nX_train = np.r_[X_train, X_outliers]\n\n# Fitting the model\nclf = IsolationForest(max_samples=100, random_state=rng)\nclf.fit(X_train)\n\n# Predictions\ny_pred_train = clf.predict(X_train)\n\n# Visualizing the data\nplt.scatter(X_train[:, 0], X_train[:, 1], c=y_pred_train, cmap='Paired')\nplt.title(\"Isolation Forest Anomaly Detection\")\nplt.xlabel(\"Feature 1\")\nplt.ylabel(\"Feature 2\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-1.png){width=587 height=449}\n:::\n:::\n\n\nIn this example, the Isolation Forest algorithm efficiently separates the outliers from the normal observations.\n\n### KNN for anomaly detection\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import NearestNeighbors\n\n# Creating sample data with some anomalies\nnp.random.seed(0)\nX_normal = np.random.rand(100, 2) * 2\nX_anomaly = np.array([[3, 3], [4, 4], [5, 5], [2.5, 3], [3, 2.5]])  # Adding more anomalies\nX = np.concatenate([X_normal, X_anomaly], axis=0)\n\n# Fitting the KNN model\nknn = NearestNeighbors(n_neighbors=2)\nknn.fit(X)\n\n# Finding the distances and indices of the nearest neighbors\ndistances, indices = knn.kneighbors(X)\n\n# Threshold for anomaly (set as a distance that seems to separate normal points from anomalies)\nthreshold = 1.0\n\n# Detecting anomalies\nis_anomaly = np.any(distances > threshold, axis=1)\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.scatter(X[is_anomaly, 0], X[is_anomaly, 1], color='red', label='Anomaly')\nplt.scatter(X[~is_anomaly, 0], X[~is_anomaly, 1], color='blue', label='Normal')\nplt.title('KNN Anomaly Detection')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.legend()\nplt.show()\n\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-3-output-1.png){width=799 height=523}\n:::\n:::\n\n\nIn this example, the KNN algorithm efficiently separates the outliers from the normal observations.\n\n\n\n## Conclusion\n\nAnomaly detection is a powerful tool in machine learning, offering significant benefits in various applications. Python's 'scikit-learn' provides accessible and efficient tools to implement these techniques. As with any machine learning task, the key to success lies in understanding your data and choosing the right algorithm for your specific use case.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}