{
  "hash": "f9d3db13dba0f245d9b2f73afc7d0e29",
  "result": {
    "markdown": "---\ntitle: \"Exploring Linear and Non-Linear Regression\"\nauthor: \"Mohaimin\"\ndate: \"2023-12-02\"\nformat: html\n---\n\n# Introduction\n\nRegression analysis is a powerful statistical method used for modeling the relationship between a dependent variable and one or more independent variables. In this blog post, we will explore two primary types of regression: linear and non-linear, using Python within the RStudio environment.\n\n## Linear Regression\n\nLinear regression is the most straightforward approach in regression analysis. It assumes a linear relationship between the input variables (independent) and the single output variable (dependent).\n\n### The Mathematical Model\n\nThe linear regression model can be represented by:\n\n$$ y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n + \\epsilon $$\n\nwhere $ \\beta_0, \\beta_1, ..., \\beta_n $ are coefficients, and $\\epsilon$ is the error term.\n\n### Python Example: Simple Linear Regression\n\nLet's start with a simple example of linear regression with one independent variable.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Sample data\nX = np.array([[5], [15], [25], [35], [45], [55]])\ny = np.array([5, 20, 14, 32, 22, 38])\n\n# Creating the linear regression model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Predictions\nX_new = np.array([[65]])\ny_pred = model.predict(X_new)\n\n# Plotting\nplt.scatter(X, y, color='blue')\nplt.plot(X, model.predict(X), color='red')\nplt.scatter(X_new, y_pred, color='green')\nplt.title('Simple Linear Regression')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](CopyOfindex_files/figure-html/cell-2-output-1.png){width=585 height=449}\n:::\n:::\n\n\n## Non Linear Regression\n\nIn contrast, non-linear regression is used when the data shows a more complex relationship that cannot be accurately described by a linear model.\nNon-linear regression can take many forms, one of which is the polynomial regression, represented by:\n$$ y = \\beta_0 + \\beta_1 x^1 + \\beta_2 x^2 + ... + \\beta_n x^n + \\epsilon $$\n\nBelow is an example of non linear regression using polynomial model. \n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Transforming the data\npolynomial_features = PolynomialFeatures(degree=2)\nX_poly = polynomial_features.fit_transform(X)\n\n# Creating a linear regression model\nmodel = LinearRegression()\nmodel.fit(X_poly, y)\n\n# Predictions\nX_new_poly = polynomial_features.fit_transform(X_new)\ny_poly_pred = model.predict(X_new_poly)\n\n# Plotting\nplt.scatter(X, y, color='blue')\nplt.plot(X, model.predict(X_poly), color='red')\nplt.scatter(X_new, y_poly_pred, color='green')\nplt.title('Polynomial Regression')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](CopyOfindex_files/figure-html/cell-3-output-1.png){width=585 height=449}\n:::\n:::\n\n\n",
    "supporting": [
      "CopyOfindex_files"
    ],
    "filters": [],
    "includes": {}
  }
}