---
title: "Anomaly Detection"
author: "Mohaimin"
date: "2023-12-04"
format: html
categories: [code]
---

# Introduction

Anomaly detection, also known as outlier detection, is a fascinating area of machine learning aimed at identifying abnormal patterns that do not conform to expected behavior. These anomalies can be crucial in various domains like fraud detection, system health monitoring, and outlier detection in data cleaning and preprocessing.

In this blog, we'll dive deep into the world of anomaly detection, exploring its concepts, methodologies, and implementation using Python.

## Fundamentals of Anomaly Detection

Anomaly detection focuses on identifying data points, events, or observations that deviate significantly from the dataset's norm. Mathematically, if we consider a dataset $D$ containing elements $x_1, x_2, ..., x_n$, an anomaly $x_i$ is a point that deviates significantly from the majority of points in $D$.

### Types of Anomalies

1. **Point Anomalies**: Single data points that are far from the rest of the data.
2. **Contextual Anomalies**: Abnormalities in a specific context but not otherwise.
3. **Collective Anomalies**: A collection of data points that are anomalous in relation to the entire dataset.

## Implementing Anomaly Detection in Python

We'll use the `scikit-learn` library in Python to demonstrate anomaly detection. Ensure you have it installed:

```{bash}
pip install scikit-learn
```

We'll use a simple dataset and Isolation Forest algorithm to detect anomaly for this example.

```{python}
import numpy as np
from sklearn.ensemble import IsolationForest
import matplotlib.pyplot as plt

# Generating sample data
rng = np.random.RandomState(42)
X = 0.3 * rng.randn(100, 2)
X_train = np.r_[X + 2, X - 2]

# Adding outliers
X_outliers = rng.uniform(low=-4, high=4, size=(20, 2))
X_train = np.r_[X_train, X_outliers]

# Fitting the model
clf = IsolationForest(max_samples=100, random_state=rng)
clf.fit(X_train)

# Predictions
y_pred_train = clf.predict(X_train)

# Visualizing the data
plt.scatter(X_train[:, 0], X_train[:, 1], c=y_pred_train, cmap='Paired')
plt.title("Isolation Forest Anomaly Detection")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()
```
In this example, the Isolation Forest algorithm efficiently separates the outliers from the normal observations.

### KNN for Anomaly Detection

```{python}
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import NearestNeighbors

# Creating sample data with some anomalies
np.random.seed(0)
X_normal = np.random.rand(100, 2) * 2
X_anomaly = np.array([[3, 3], [4, 4], [5, 5], [2.5, 3], [3, 2.5]])  # Adding more anomalies
X = np.concatenate([X_normal, X_anomaly], axis=0)

# Fitting the KNN model
knn = NearestNeighbors(n_neighbors=2)
knn.fit(X)

# Finding the distances and indices of the nearest neighbors
distances, indices = knn.kneighbors(X)

# Threshold for anomaly (set as a distance that seems to separate normal points from anomalies)
threshold = 1.0

# Detecting anomalies
is_anomaly = np.any(distances > threshold, axis=1)

# Plotting
plt.figure(figsize=(10, 6))
plt.scatter(X[is_anomaly, 0], X[is_anomaly, 1], color='red', label='Anomaly')
plt.scatter(X[~is_anomaly, 0], X[~is_anomaly, 1], color='blue', label='Normal')
plt.title('KNN Anomaly Detection')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.show()


```
In this example, the KNN algorithm efficiently separates the outliers from the normal observations.

## Conclusion

Anomaly detection is a powerful tool in machine learning, offering significant benefits in various applications. Python's 'scikit-learn' provides accessible and efficient tools to implement these techniques. As with any machine learning task, the key to success lies in understanding your data and choosing the right algorithm for your specific use case.